{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating and Error Components Model via GMM\n",
    "### by [Jason DeBacker](https://jasondebacker.com), September 2017\n",
    "\n",
    "This Jupyter Notebook illustrates how estimate the stationary error components model used in DeBacker, Heim, Panousi, Ramnath, and Vidangos (*Brookings Papers on Economic Activity*, Spring 2013) (hereafter, DHPRV).\n",
    "\n",
    "\n",
    "## Moment conditions\n",
    "\n",
    "The theoretical moment conditions are given by:\n",
    "\n",
    "$$ g_{a,t,k}(\\Theta_{0}) = E \\left[cov(\\xi^{i}_{a,t},\\xi^{i}_{a+k,t+k})\\right] -cov(a,t,k; \\Theta_{0}) = 0 $$\n",
    "\n",
    "Where $cov(a,t,k)$ are the theoretical covariances for individuals of age $a$, in year $t$, at lead $k$.  These are given as:\n",
    "\n",
    "  \\begin{equation*}\n",
    "    \\begin{split}\n",
    "      cov(a,t,k; \\Theta) & = \\sigma^{2}_{\\alpha} + \\psi^{k}var(p^{i}_{a,t}) + \\\\ & \\quad\\quad\\quad \\mathbf{1}[k=0](1+\\mathbf{1}[a\\geq2]\\theta^{2}_{1}+\\mathbf{1}[a\\geq3]\\theta^{2}_{2})\\sigma^{2}_{\\varepsilon} + \\\\\n",
    "      & \\quad\\quad\\quad \\mathbf{1}[k=1](\\theta_{1}+\\mathbf{1}[a\\geq2]\\theta_{1}\\theta_{2})\\sigma^{2}_{\\varepsilon} + \\\\\n",
    "      & \\quad\\quad\\quad \\mathbf{1}[k=2]\\theta_{2}\\sigma^{2}_{\\varepsilon}\n",
    "    \\end{split}\n",
    "  \\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "The sample analogue to these conditions are:\n",
    "\n",
    "$$ \\tilde{g}_{a,t,k}(\\Theta_{0}) = \\frac{\\sum_{i=1}^{n}(\\xi^{i}_{a,t}\\xi^{i}_{a+k,t+k})}{n-1} -cov(a,t,k; \\Theta_{0}) = 0 $$\n",
    "\n",
    "Thus the first step in our method of moments estimator is to compute the covariances from the data.\n",
    "\n",
    "## The data\n",
    "\n",
    "We'll begin the exercise in this notebook by reading in a Stata datafile that contains the computed sample covariances.  These were constructed from a panel of tax returns spanning the 1987 to 2009 period.  The unit of analysis are males, aged 25-60 with at least $2,575 (in constant, 2005$) in labor income.  Labor income is defined as wages and salaries plus self-employment income.  \n",
    "\n",
    "The covariances are computed on the residuals from regressing the log of labor income on dummy variables for age, separately by year.\n",
    "\n",
    "The covariances are then computed for all possible combinations of age, year, and lead.\n",
    "\n",
    "Let's read in the data and look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import packages we'll use here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yrvar</th>\n",
       "      <th>hvar</th>\n",
       "      <th>jvar</th>\n",
       "      <th>hpjvar</th>\n",
       "      <th>covvar</th>\n",
       "      <th>wgtvar</th>\n",
       "      <th>covvarfd</th>\n",
       "      <th>wgtvarfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.438955</td>\n",
       "      <td>329.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.289566</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.261525</td>\n",
       "      <td>302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.235245</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.177744</td>\n",
       "      <td>283.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yrvar  hvar  jvar  hpjvar    covvar  wgtvar  covvarfd  wgtvarfd\n",
       "0   1987     1     0       1  0.438955   329.0       NaN       NaN\n",
       "1   1987     1     1       2  0.289566   306.0       NaN       NaN\n",
       "2   1987     1     2       3  0.261525   302.0       NaN       NaN\n",
       "3   1987     1     3       4  0.235245   290.0       NaN       NaN\n",
       "4   1987     1     4       5  0.177744   283.0       NaN       NaN"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the covariance data\n",
    "covs_data = pd.read_stata('CovsData_labinc_CAL.dta')\n",
    "covs_data.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yrvar</th>\n",
       "      <th>hvar</th>\n",
       "      <th>jvar</th>\n",
       "      <th>hpjvar</th>\n",
       "      <th>covvar</th>\n",
       "      <th>wgtvar</th>\n",
       "      <th>covvarfd</th>\n",
       "      <th>wgtvarfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7084.000000</td>\n",
       "      <td>7084.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1994.866279</td>\n",
       "      <td>15.366279</td>\n",
       "      <td>6.267442</td>\n",
       "      <td>21.633721</td>\n",
       "      <td>0.420292</td>\n",
       "      <td>232.583298</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>213.861374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.652031</td>\n",
       "      <td>9.071330</td>\n",
       "      <td>5.107145</td>\n",
       "      <td>9.071330</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>51.063007</td>\n",
       "      <td>0.059922</td>\n",
       "      <td>45.461811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089425</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-0.117507</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1990.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.318830</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>-0.011552</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.501245</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.031453</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>0.377932</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             yrvar         hvar         jvar       hpjvar       covvar  \\\n",
       "count  7912.000000  7912.000000  7912.000000  7912.000000  7912.000000   \n",
       "mean   1994.866279    15.366279     6.267442    21.633721     0.420292   \n",
       "std       5.652031     9.071330     5.107145     9.071330     0.142618   \n",
       "min    1987.000000     1.000000     0.000000     1.000000     0.089425   \n",
       "25%    1990.000000     8.000000     2.000000    15.000000     0.318830   \n",
       "50%    1994.000000    15.000000     5.000000    22.000000     0.403844   \n",
       "75%    1999.000000    22.000000    10.000000    29.000000     0.501245   \n",
       "max    2009.000000    36.000000    22.000000    36.000000     1.031453   \n",
       "\n",
       "            wgtvar     covvarfd     wgtvarfd  \n",
       "count  7912.000000  7084.000000  7084.000000  \n",
       "mean    232.583298     0.013806   213.861374  \n",
       "std      51.063007     0.059922    45.461811  \n",
       "min      81.000000    -0.117507    76.000000  \n",
       "25%     201.000000    -0.011552   186.000000  \n",
       "50%     239.000000    -0.001709   218.000000  \n",
       "75%     268.000000     0.009143   245.000000  \n",
       "max     367.000000     0.377932   342.000000  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covs_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 7,912 different covariances measured from the data (we'll ignore the \"fd\", or first-differenced\" covariances, and just estimate the model for the levels here).\n",
    "\n",
    "The variables names are as follows:\n",
    "* `yrvar` = year\n",
    "* `hvar` = age\n",
    "* `jvar` = lead\n",
    "* `hpjvar` = age + lead\n",
    "* `covvar` = covariance\n",
    "* `wgtvar` = sample weights = number of observations used to compute the sample covariance.\n",
    "\n",
    "# Clean the data\n",
    "\n",
    "Now let's make a few adjustments to these data made in DHPRV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yrvar</th>\n",
       "      <th>hvar</th>\n",
       "      <th>jvar</th>\n",
       "      <th>hpjvar</th>\n",
       "      <th>covvar</th>\n",
       "      <th>wgtvar</th>\n",
       "      <th>covvarfd</th>\n",
       "      <th>wgtvarfd</th>\n",
       "      <th>cohort</th>\n",
       "      <th>yearpj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7084.000000</td>\n",
       "      <td>7084.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "      <td>7912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1994.866279</td>\n",
       "      <td>15.366279</td>\n",
       "      <td>6.267442</td>\n",
       "      <td>21.633721</td>\n",
       "      <td>0.420292</td>\n",
       "      <td>232.583298</td>\n",
       "      <td>0.013806</td>\n",
       "      <td>213.861374</td>\n",
       "      <td>1980.500000</td>\n",
       "      <td>2001.133721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.652031</td>\n",
       "      <td>9.071330</td>\n",
       "      <td>5.107145</td>\n",
       "      <td>9.071330</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>51.063007</td>\n",
       "      <td>0.059922</td>\n",
       "      <td>45.461811</td>\n",
       "      <td>10.059474</td>\n",
       "      <td>5.652031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1987.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089425</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>-0.117507</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>1987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1990.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.318830</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>-0.011552</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.403844</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>1980.500000</td>\n",
       "      <td>2002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.501245</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.031453</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>0.377932</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             yrvar         hvar         jvar       hpjvar       covvar  \\\n",
       "count  7912.000000  7912.000000  7912.000000  7912.000000  7912.000000   \n",
       "mean   1994.866279    15.366279     6.267442    21.633721     0.420292   \n",
       "std       5.652031     9.071330     5.107145     9.071330     0.142618   \n",
       "min    1987.000000     1.000000     0.000000     1.000000     0.089425   \n",
       "25%    1990.000000     8.000000     2.000000    15.000000     0.318830   \n",
       "50%    1994.000000    15.000000     5.000000    22.000000     0.403844   \n",
       "75%    1999.000000    22.000000    10.000000    29.000000     0.501245   \n",
       "max    2009.000000    36.000000    22.000000    36.000000     1.031453   \n",
       "\n",
       "            wgtvar     covvarfd     wgtvarfd       cohort       yearpj  \n",
       "count  7912.000000  7084.000000  7084.000000  7912.000000  7912.000000  \n",
       "mean    232.583298     0.013806   213.861374  1980.500000  2001.133721  \n",
       "std      51.063007     0.059922    45.461811    10.059474     5.652031  \n",
       "min      81.000000    -0.117507    76.000000  1952.000000  1987.000000  \n",
       "25%     201.000000    -0.011552   186.000000  1973.000000  1997.000000  \n",
       "50%     239.000000    -0.001709   218.000000  1980.500000  2002.000000  \n",
       "75%     268.000000     0.009143   245.000000  1988.000000  2006.000000  \n",
       "max     367.000000     0.377932   342.000000  2009.000000  2009.000000  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the data\n",
    "# drop if missing value for the covariance\n",
    "covs_data = covs_data[covs_data.covvar.isnull() != True ]\n",
    "\n",
    "\n",
    "# * Create dummy variable Dj0, which equals 1 if jvar==0 and equals 0 otherwise\n",
    "covs_data['Dj0'] = covs_data['jvar'] == 0\n",
    "\n",
    "# ********************************************************************************\n",
    "# * Pick observations used for estimation\n",
    "# ********************************************************************************\n",
    "year1 = 1987\n",
    "year2 = 1988\n",
    "yearT = 2009\n",
    "\n",
    "# Define cohorts - those who were 25 in 1952 were 60 in 1987\n",
    "cohort1 = 1952  # first cohort\n",
    "cohortT = 2009  # last cohort\n",
    "\n",
    "covs_data['cohort'] = covs_data['yrvar'] - covs_data['hvar'] + 1\n",
    "covs_data[(covs_data['cohort'] >= cohort1) & (covs_data['cohort'] <= cohortT)]\n",
    "covs_data[(covs_data['yrvar'] >= year1) & (covs_data['yrvar'] <= yearT)]\n",
    "\n",
    "# * Make sure that \"future\" years used to compute autocovariances do not fall \n",
    "# * outside of [year1,yearT] range:\n",
    "covs_data['yearpj'] = covs_data['cohort'] -1 + covs_data['hvar'] + covs_data['jvar']\n",
    "covs_data[(covs_data['yearpj'] >= year1) & (covs_data['yearpj'] <= yearT)]\n",
    "covs_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears these restrictions make no difference here - we had no missing values, no observations outside the potential ranges of values.\n",
    "\n",
    "## Theoretical covariances\n",
    "\n",
    "Now, let's define those theoretical covariances.  Recall, these are given by:\n",
    "\n",
    "  \\begin{equation*}\n",
    "    \\begin{split}\n",
    "      cov(a,t,k; \\Theta) & = \\sigma^{2}_{\\alpha} + \\psi^{k}var(p^{i}_{a,t}) + \\\\ & \\quad\\quad\\quad \\mathbf{1}[k=0](1+\\mathbf{1}[a\\geq2]\\theta^{2}_{1}+\\mathbf{1}[a\\geq3]\\theta^{2}_{2})\\sigma^{2}_{\\varepsilon} + \\\\\n",
    "      & \\quad\\quad\\quad \\mathbf{1}[k=1](\\theta_{1}+\\mathbf{1}[a\\geq2]\\theta_{1}\\theta_{2})\\sigma^{2}_{\\varepsilon} + \\\\\n",
    "      & \\quad\\quad\\quad \\mathbf{1}[k=2]\\theta_{2}\\sigma^{2}_{\\varepsilon}\n",
    "    \\end{split}\n",
    "  \\end{equation*}\n",
    "  \n",
    "There is a little more detail needed to compute $var(p^{i}_{a,t})$ (you can refer to DHPRV for more detail on this, but it can also be seen in the function we'll define below).  Let's call this function that returns the theoretical covariances `model_cov` and define it as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to compute theoretical covariances.\n",
    "def model_cov(Theta):\n",
    "    '''\n",
    "    Compute model implied covariances given parameters.\n",
    "    \n",
    "    Args:\n",
    "        Theta: A length 6 tuple, model parameters (sigma2_alpha,\n",
    "               sigma2_eta, sigma2_eps, psi, theta1, theta2)\n",
    "    \n",
    "    Returns:\n",
    "        covs_model: A dataframe with covariances for all years (t),\n",
    "                    ages (h), and leads (k)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    sigma2_alpha, sigma2_eta, sigma2_eps, psi, theta1, theta2 = Theta\n",
    "    \n",
    "    # compute var(p^{i}_{a,t})\n",
    "    varp = np.empty((2009-1952, 37))\n",
    "    for cohort in range(1952, 2010):\n",
    "        for age in range(1, 37):\n",
    "            yr = cohort + age - 1\n",
    "            yrm1  = yr - 1\n",
    "            yrm2  = yr - 2\n",
    "            agem1 = age - 1\n",
    "            if yr <= 2009:\n",
    "                if yr == 1987:\n",
    "                    varp[yr - 1987, age] = sigma2_eta * (1 - psi ** (2 * age)) / (1 - psi ** 2)\n",
    "                if age == 1:\n",
    "                    varp[yr - 1987, age] = sigma2_eta\n",
    "                if age == 2:\n",
    "                    varp[yr - 1987, age] = (psi ** 2) * varp[yrm1 - 1987, agem1] + sigma2_eta\n",
    "                if age >= 3:\n",
    "                    varp[yr - 1987, age] = (psi ** 2) * varp[yrm1 - 1987, agem1] + sigma2_eta\n",
    "                                                         \n",
    "    # Compute theoretical covariancea                                 \n",
    "    covs_dict = {'year': [], 'age': [], 'lead': [], 'cov': []}\n",
    "    for t in range(1987, 2010):\n",
    "        maxK = 2009 - t\n",
    "        for h in range(1, 37):\n",
    "            for k in range(maxK + 1):\n",
    "                cov = (sigma2_alpha + ((psi ** k) * varp[t - 1987, h]) +\n",
    "                       ((k==0) * (1 + ((h>=2) * (theta1 ** 2)) + ((h>=3) * (theta2 ** 2))) * sigma2_eps) +\n",
    "                       ((k==1) * (theta1 + ((h>=2) * theta1 * theta2)) * sigma2_eps) +\n",
    "                       ((k==2) * theta2 * sigma2_eps))\n",
    "                       # update dictionary\n",
    "                covs_dict['cov'].append(cov)\n",
    "                covs_dict['year'].append(t)\n",
    "                covs_dict['age'].append(h)\n",
    "                covs_dict['lead'].append(k)\n",
    "\n",
    "    # create dataframe with dictionary\n",
    "    covs_model = pd.DataFrame(covs_dict)\n",
    "    \n",
    "    return covs_model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the statistical objective function\n",
    "\n",
    "Now we have the covariances from the data and a function that returns the model covariances for a given set of parameters.  Now we just need to define a statistical objective function that can be minimized.  In our case, the moment conditions can be represented by a set of residuals (the difference between the data and model moments).  We can thus use a nonlinear least squares estimator.  \n",
    "\n",
    "To esimate the model parameters via nonlinear least squares, we'll call the `scipy.optimize.least_squares()` method.  The function that is passed as an argument to this method is one that returns the vector of residuals. So we'll need our function to return the errors in these moment conditions.\n",
    "\n",
    "We name this function `resids()` and define it as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to return residuals - for nonlinear least squares estimator\n",
    "def resids(Theta, covs_data):\n",
    "    '''\n",
    "    Compute the (weighted) residuals from the moment conditions.\n",
    "    \n",
    "    Args:\n",
    "        covs_data: Dataframe of covariances from the data\n",
    "        covs_model: Dataframe of model implied covariances\n",
    "        \n",
    "    Returns:\n",
    "        resids_wgt: Vector of weighted differences between the model and data moments\n",
    "    '''\n",
    "    # Find the model covariances impllied by parameter vector Theta\n",
    "    covs_model = model_cov(Theta)\n",
    "    \n",
    "    # merge the two dataframes together\n",
    "    data_model = covs_data.merge(covs_model, how='left', left_on=['yrvar', 'hvar', 'jvar'],\n",
    "                                 right_on=['year', 'age', 'lead'], copy=True, indicator=False)\n",
    "    \n",
    "    # compute the weighted differences between data and model covariances\n",
    "    # Note that use sqrt of the weight since it will be squares in f(x)=r^Tr\n",
    "    resids_wgt = np.array(((data_model['covvar'] - data_model['cov']) *\n",
    "                          (data_model['wgtvar'] ** (1 / 2))).values)\n",
    "\n",
    "    \n",
    "    return resids_wgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the optimization routine\n",
    "\n",
    "With the moment conditions not defined, we are almost ready to call our least squares estimator.  But before we do, we'll need to provide our initial guesses and set any bounds on the parameter estimates (if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initial guesses at the parameter values\n",
    "Theta0 = (0.1, 0.001, 0.1, 0.9, 0.0, 0.0)\n",
    "\n",
    "# Set bounds on parameters\n",
    "bnds = ([0, 0, 0, -np.inf, -np.inf, -np.inf],\n",
    "        [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf])\n",
    "\n",
    "# Call minimzer to minimize the sum of square residuals\n",
    "# note the comma after covs_data - this is critical to pass the argument in the right way\n",
    "nls_results = opt.least_squares(resids, Theta0, bounds=bnds, method='trf', args=(covs_data,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We'll now view the results.  The object returned from `scipy.optimize.least_squares()` is a dictionary with 12 key value pairs.  The dictionary includes the parameter estimates (key = `'x'`) and a lot of other information about the estimation such as whether the estimator converged, the number of function evaluations, the gradient and jacobian at the parameters estimate, and more.\n",
    "\n",
    "Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " active_mask: array([0, 0, 0, 0, 0, 0])\n",
       "        cost: 4027.9525840678143\n",
       "         fun: array([ 0.54911543,  0.39988771,  0.26317226, ...,  1.68632693,\n",
       "        0.19709438, -0.60835445])\n",
       "        grad: array([ -1.81622029e-05,  -8.60051719e-05,   4.35267855e-05,\n",
       "        -5.24037910e-03,   3.47759158e-03,   1.29587262e-02])\n",
       "         jac: array([[ -18.13835716,  -18.13835716,  -18.13835716,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [ -17.49285507,  -16.83412089,   -3.99847781,   -0.51213383,\n",
       "          -3.19444842,    0.        ],\n",
       "       [ -17.37814713,  -16.09396146,   -2.1390215 ,   -0.97923286,\n",
       "           0.        ,   -3.17350113],\n",
       "       ..., \n",
       "       [ -14.69693851, -184.26261251,  -15.68748537, -110.2560778 ,\n",
       "          -1.22694774,   -0.66069923],\n",
       "       [ -13.9283886 , -175.65098643,  -14.86713647, -106.60892073,\n",
       "          -1.16278672,   -0.62614905],\n",
       "       [ -13.49073792, -171.05035287,  -14.39998893, -105.21529097,\n",
       "          -1.12625023,   -0.60647452]])\n",
       "     message: '`ftol` termination condition is satisfied.'\n",
       "        nfev: 11\n",
       "        njev: 9\n",
       "  optimality: 0.012958726210200666\n",
       "      status: 2\n",
       "     success: True\n",
       "           x: array([ 0.19679008,  0.02927674,  0.18261447,  0.96234267,  0.22857777,\n",
       "        0.12308686])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show nonlinear least squares estimation results\n",
    "nls_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An alternative estimator\n",
    "\n",
    "We can also use a minimizer that is not specifically for a least squares problem.  In this case, we'll need to define our statistical objective function that we want to minimize.  We'll call this `ssr()` since it's the sum of squared residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the statistical objective function\n",
    "def ssr(Theta, covs_data):\n",
    "    '''\n",
    "    Compute the (weighted) sum of squared residuals from the moment conditions.\n",
    "    \n",
    "    Args:\n",
    "        covs_data: Dataframe of covariances from the data\n",
    "        covs_model: Dataframe of model implied covariances\n",
    "        \n",
    "    Returns:\n",
    "        sumsq: Weighted sum of squared residuals showing difference\n",
    "                between data and model covariances.\n",
    "    '''\n",
    "    \n",
    "    # Find the model covariances impllied by parameter vector Theta\n",
    "    covs_model = model_cov(Theta)\n",
    "    \n",
    "    # merge the two dataframes together\n",
    "    data_model = covs_data.merge(covs_model, how='left', left_on=['yrvar', 'hvar', 'jvar'],\n",
    "                                 right_on=['year', 'age', 'lead'], copy=True, indicator=False)\n",
    "    \n",
    "    # compute differences between data and model covariances\n",
    "    data_model['resid'] = data_model['covvar'] - data_model['cov']\n",
    "    \n",
    "    # compute weighted SSR\n",
    "    sumsq = ((data_model['resid'] ** 2) * (data_model['wgtvar'])).sum()\n",
    "    \n",
    "    return sumsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to call the `ssr()` function through a minimization routine.  Here, we'll use a modified BFGS algorithm that will allow for bounds on the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 8055.905176089554\n",
       " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([-0.00654836,  0.01227818, -0.00345608,  0.00318323, -0.00145519,\n",
       "        0.0001819 ])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 518\n",
       "      nit: 53\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([ 0.19679028,  0.02927667,  0.18261471,  0.96234275,  0.22857783,\n",
       "        0.12308503])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial guesses at the parameter values\n",
    "Theta0 = (0.1, 0.001, 0.1, 0.9, 0.0, 0.0)\n",
    "\n",
    "# Set bounds on parameters\n",
    "bnds = ((0, None), (0, None), (0, None),\n",
    "        (None, None), (None, None), (None, None))\n",
    "\n",
    "# Use a general purpuse minimizer to minimize the SSR\n",
    "min_results = opt.minimize(ssr, Theta0, args=(covs_data,),\n",
    "                           method=\"L-BFGS-B\", bounds=bnds, tol=1e-15)\n",
    "\n",
    "min_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "We'll omit the discussion of standard errors, but they can be computed using either the theoretical standard errors (which will rely on the Jacobian of the function) or via boostrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
